{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b416e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293K â†’ UPTAKE: 8 files\n",
      "293K â†’ TIME: 8 files\n",
      "313K â†’ UPTAKE: 8 files\n",
      "313K â†’ TIME: 8 files\n",
      "\n",
      " Counter({7766: 16, 8267: 10, 7768: 5, 7668: 1})\n",
      "                                    name     HENRY      0.01      0.05  \\\n",
      "0  1499489-acs.cgd.6b01265_1499490_clean  0.000007  0.007308  0.037157   \n",
      "1                           ABAYIO_clean  0.000005  0.004859  0.024731   \n",
      "2                           ABAYOU_clean  0.000005  0.005039  0.025003   \n",
      "3                           ABESUX_clean  0.000001  0.001308  0.006426   \n",
      "4                           ABETAE_clean  0.000001  0.001280  0.006447   \n",
      "\n",
      "        0.1       0.5         1         5        15  \n",
      "0  0.073651  0.362091  0.695022  2.768486  5.585666  \n",
      "1  0.047941  0.225723  0.427736  1.658196  3.672871  \n",
      "2  0.050040  0.231845  0.438342  1.706788  3.721950  \n",
      "3  0.013009  0.063890  0.123668  0.536088  1.178772  \n",
      "4  0.012686  0.063002  0.124638  0.532293  1.186673  \n",
      "\n",
      "âœ… ë³‘í•© \n",
      "ğŸ“‚ ./273K_uptake_pivot.csv\n",
      "  ì´ MOF ê°œìˆ˜       : 8267\n",
      "  NaN ì œê±°ëœ ê°œìˆ˜   : 501\n",
      "  ìœ íš¨ MOF ê°œìˆ˜     : 7766\n",
      "  ë¹„ë‹¨ì¡° MOF ê°œìˆ˜   : 1\n",
      "  ë¹„ë‹¨ì¡° ë¹„ìœ¨       : 0.000\n",
      "--------------------------------------------------\n",
      "ğŸ“‚ ./293K_uptake_pivot.csv\n",
      "  ì´ MOF ê°œìˆ˜       : 7766\n",
      "  NaN ì œê±°ëœ ê°œìˆ˜   : 0\n",
      "  ìœ íš¨ MOF ê°œìˆ˜     : 7766\n",
      "  ë¹„ë‹¨ì¡° MOF ê°œìˆ˜   : 1\n",
      "  ë¹„ë‹¨ì¡° ë¹„ìœ¨       : 0.000\n",
      "--------------------------------------------------\n",
      "ğŸ“‚ ./313K_uptake_pivot.csv\n",
      "  ì´ MOF ê°œìˆ˜       : 8267\n",
      "  NaN ì œê±°ëœ ê°œìˆ˜   : 599\n",
      "  ìœ íš¨ MOF ê°œìˆ˜     : 7668\n",
      "  ë¹„ë‹¨ì¡° MOF ê°œìˆ˜   : 0\n",
      "  ë¹„ë‹¨ì¡° ë¹„ìœ¨       : 0.000\n",
      "--------------------------------------------------\n",
      "                      file  n_total  n_drop_nan  n_valid  n_non_mono  \\\n",
      "0  ./273K_uptake_pivot.csv     8267         501     7766           1   \n",
      "1  ./293K_uptake_pivot.csv     7766           0     7766           1   \n",
      "2  ./313K_uptake_pivot.csv     8267         599     7668           0   \n",
      "\n",
      "   ratio_non_mono  \n",
      "0        0.000129  \n",
      "1        0.000129  \n",
      "2        0.000000  \n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "FOLDER1 = [\"293K/\", \"293K/\", \"313K/\"]\n",
    "FOLDER2 = [\"UPTAKE\", \"TIME\"]\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# defaultdictë¥¼ ì‚¬ìš©í•´ ì¤‘ì²© ë”•ì…”ë„ˆë¦¬ ìë™ ìƒì„±\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def nested_dict():\n",
    "    return defaultdict(nested_dict)\n",
    "\n",
    "DICT = nested_dict()\n",
    "DF_DICT = nested_dict()\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# íŒŒì¼ íƒìƒ‰ ë° ë”•ì…”ë„ˆë¦¬ ì €ì¥\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for F1 in FOLDER1:\n",
    "    for F2 in FOLDER2:\n",
    "        path = os.path.join(F1, F2)\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "\n",
    "        for fname in os.listdir(path):\n",
    "            file_path = os.path.join(path, fname)\n",
    "            if not fname.endswith(\".csv\"):\n",
    "                continue\n",
    "\n",
    "            DF = pd.read_csv(file_path)\n",
    "            DICT[F1.rstrip(\"/\")][F2][fname] = len(DF)\n",
    "            DF_DICT[F1.rstrip(\"/\")][F2][fname] = DF\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ê³„ì¸µ êµ¬ì¡° ì˜ˆì‹œ ì¶œë ¥\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "for T in DICT:\n",
    "    for typ in DICT[T]:\n",
    "        print(f\"{T} â†’ {typ}: {len(DICT[T][typ])} files\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì „ì²´ ì¹´ìš´íŠ¸ ìš”ì•½\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "all_lengths = [len_df for temp in DICT.values()\n",
    "                        for typ in temp.values()\n",
    "                        for len_df in typ.values()]\n",
    "\n",
    "print(\"\\n\", Counter(all_lengths))\n",
    "\n",
    "\n",
    "## Uptakeë°ì´í„° í•©ì¹˜ê¸°\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# íŒŒì¼ ê²½ë¡œ ì§€ì •\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "T2 = 293\n",
    "T = str(T2) + \"K\"\n",
    "PATHS = {\n",
    "    \"HENRY\": f\"./{T}/UPTAKE/{T2}_HENRY.csv\",\n",
    "    \"0.01\": f\"./{T}/UPTAKE/{T2}_0.01.csv\",\n",
    "    \"0.05\": f\"./{T}/UPTAKE/{T2}_0.05.csv\",\n",
    "    \"0.1\":  f\"./{T}/UPTAKE/{T2}_0.1.csv\",\n",
    "    \"0.5\":  f\"./{T}/UPTAKE/{T2}_0.5.csv\",\n",
    "    \"1\":    f\"./{T}/UPTAKE/{T2}_1.csv\",\n",
    "    \"5\":    f\"./{T}/UPTAKE/{T2}_5.csv\",\n",
    "    \"15\":   f\"./{T}/UPTAKE/{T2}_15.csv\"\n",
    "}\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# CSV ì½ê³ , HENRYëŠ” henry_coeff / ë‚˜ë¨¸ì§€ëŠ” abs_mol_per_kg_framework ì‚¬ìš©\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "dfs = []\n",
    "for label, path in PATHS.items():\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    if label == \"HENRY\":\n",
    "        if \"henry_coeff\" not in df.columns:\n",
    "            raise KeyError(f\"'{path}' íŒŒì¼ì—ì„œ henry_coeff ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        value_col = \"henry_coeff\"\n",
    "    else:\n",
    "        if \"abs_mol_per_kg_framework\" not in df.columns:\n",
    "            raise KeyError(f\"'{path}' íŒŒì¼ì—ì„œ abs_mol_per_kg_framework ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        value_col = \"abs_mol_per_kg_framework\"\n",
    "    \n",
    "    df = df[[\"name\", value_col]].rename(columns={value_col: label})\n",
    "    dfs.append(df)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# name ê¸°ì¤€ ë³‘í•©\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "merged_df = reduce(lambda left, right: pd.merge(left, right, on=\"name\", how=\"outer\"), dfs)\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì—´ ìˆœì„œ ì •ë ¬ ë° ê²°ê³¼ í™•ì¸\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "cols_order = [\"name\"] + list(PATHS.keys())\n",
    "merged_df = merged_df[cols_order]\n",
    "\n",
    "print(merged_df.head())\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì €ì¥\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "merged_df.to_csv(f\"./{T}_uptake_pivot.csv\", index=False)\n",
    "print(\"\\nâœ… ë³‘í•© \")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def check_monotonic_ratio(path, verbose=True):\n",
    "    \"\"\"\n",
    "    ë‹¨ì¡° ì¦ê°€í•˜ì§€ ì•ŠëŠ” MOF ë¹„ìœ¨ ê³„ì‚° ì—”ì§„\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        uptake pivot CSV ê²½ë¡œ\n",
    "    verbose : bool\n",
    "        Trueë©´ í†µê³„ ì¶œë ¥\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        {'file': ..., 'n_total': ..., 'n_drop_nan': ..., 'n_valid': ...,\n",
    "         'n_non_mono': ..., 'ratio_non_mono': ...}\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.set_index('name')\n",
    "\n",
    "    # ì—´ ìˆœì„œ ìë™ ì¸ì‹ (HENRY ì œì™¸ í›„ ìˆ«ììˆœ ì •ë ¬)\n",
    "    cols = [c for c in df.columns if c != \"name\"]\n",
    "    try:\n",
    "        cols_sorted = [\"HENRY\"] + sorted([c for c in cols if c != \"HENRY\"], key=lambda x: float(x))\n",
    "    except:\n",
    "        cols_sorted = cols\n",
    "\n",
    "    df = df[cols_sorted]\n",
    "\n",
    "    n_total = len(df)\n",
    "\n",
    "    # NaN ìˆëŠ” í–‰ ì œê±°\n",
    "    df_no_nan = df.dropna(subset=cols_sorted)\n",
    "    n_drop_nan = n_total - len(df_no_nan)\n",
    "\n",
    "    # ë‹¨ì¡°ì„± ê²€ì‚¬\n",
    "    non_mono = []\n",
    "    for idx, row in df_no_nan.iterrows():\n",
    "        values = row.values\n",
    "        if not np.all(np.diff(values) >= 0):  # ë‹¨ì¡° ì¦ê°€ ì‹¤íŒ¨\n",
    "            non_mono.append(idx)\n",
    "\n",
    "    n_non_mono = len(non_mono)\n",
    "    n_valid = len(df_no_nan)\n",
    "    ratio = n_non_mono / n_valid if n_valid > 0 else np.nan\n",
    "\n",
    "    result = {\n",
    "        'file': path,\n",
    "        'n_total': n_total,\n",
    "        'n_drop_nan': n_drop_nan,\n",
    "        'n_valid': n_valid,\n",
    "        'n_non_mono': n_non_mono,\n",
    "        'ratio_non_mono': ratio\n",
    "    }\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"ğŸ“‚ {path}\")\n",
    "        print(f\"  ì´ MOF ê°œìˆ˜       : {n_total}\")\n",
    "        print(f\"  NaN ì œê±°ëœ ê°œìˆ˜   : {n_drop_nan}\")\n",
    "        print(f\"  ìœ íš¨ MOF ê°œìˆ˜     : {n_valid}\")\n",
    "        print(f\"  ë¹„ë‹¨ì¡° MOF ê°œìˆ˜   : {n_non_mono}\")\n",
    "        print(f\"  ë¹„ë‹¨ì¡° ë¹„ìœ¨       : {ratio:.3f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    return result\n",
    "def analyze_all_temperatures(paths):\n",
    "    results = [check_monotonic_ratio(p) for p in paths]\n",
    "    return pd.DataFrame(results)\n",
    "PATHS = [\n",
    "    \"./273K_uptake_pivot.csv\",\n",
    "    \"./293K_uptake_pivot.csv\",\n",
    "    \"./313K_uptake_pivot.csv\",\n",
    "]\n",
    "summary = analyze_all_temperatures(PATHS)\n",
    "print(summary)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97163146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HENRY</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [HENRY, 0.01, 0.05, 0.1, 0.5, 1, 5, 15]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ë‹¨ì¡°ì¦ê°€ ê¹¨ì§„ ê²ƒ ì‹ë³„\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def extract_nonmonotonic_mofs(path, save_csv=True):\n",
    "    \"\"\"\n",
    "    ë‹¨ì¡° ì¦ê°€ê°€ ê¹¨ì§„ MOFë§Œ ì¶”ì¶œí•˜ëŠ” ì—”ì§„ í•¨ìˆ˜\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        uptake pivot CSV ê²½ë¡œ\n",
    "    save_csv : bool, optional\n",
    "        Trueë©´ \"_nonmonotonic.csv\" íŒŒì¼ë¡œ ì €ì¥\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    nonmono_df : pd.DataFrame\n",
    "        ë‹¨ì¡° ìœ„ë°˜ MOFë“¤ë§Œ ë‹´ì€ DataFrame\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.set_index('name')\n",
    "\n",
    "    # ì—´ ìˆœì„œ ì •ë¦¬ (HENRY ì œì™¸ í›„ ìˆ«ììˆœ ì •ë ¬)\n",
    "    cols = [c for c in df.columns if c != 'name']\n",
    "    try:\n",
    "        cols_sorted = ['HENRY'] + sorted([c for c in cols if c != 'HENRY'], key=lambda x: float(x))\n",
    "    except:\n",
    "        cols_sorted = cols\n",
    "\n",
    "    df = df[cols_sorted]\n",
    "    df_no_nan = df.dropna(subset=cols_sorted)\n",
    "\n",
    "    # ë‹¨ì¡°ì„± ê²€ì‚¬\n",
    "    mask_nonmono = []\n",
    "    for _, row in df_no_nan.iterrows():\n",
    "        values = row.values\n",
    "        mask_nonmono.append(not np.all(np.diff(values) >= 0))\n",
    "    nonmono_df = df_no_nan[mask_nonmono]\n",
    "\n",
    "    if save_csv:\n",
    "        out_path = path.replace(\".csv\", \"_nonmonotonic.csv\")\n",
    "        nonmono_df.to_csv(out_path)\n",
    "        print(f\"âœ… {len(nonmono_df)}ê°œ MOF ì €ì¥ ì™„ë£Œ â†’ {out_path}\")\n",
    "\n",
    "    return nonmono_df\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì—¬ëŸ¬ ì˜¨ë„ íŒŒì¼ì— ëŒ€í•´ ìë™ ì²˜ë¦¬\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def extract_all_nonmonotonic(paths):\n",
    "    results = {}\n",
    "    for p in paths:\n",
    "        results[p] = extract_nonmonotonic_mofs(p, save_csv=False)\n",
    "    return results\n",
    "\n",
    "\n",
    "PATHS = [\n",
    "    \"./273K_uptake_pivot.csv\",\n",
    "    \"./293K_uptake_pivot.csv\",\n",
    "    \"./313K_uptake_pivot.csv\"\n",
    "]\n",
    "all_nonmono = extract_all_nonmonotonic(PATHS)\n",
    "all_nonmono.keys()\n",
    "all_nonmono[\"./273K_uptake_pivot.csv\"]\n",
    "all_nonmono[\"./293K_uptake_pivot.csv\"]\n",
    "all_nonmono[\"./313K_uptake_pivot.csv\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "160ce1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Horizontal ë³‘í•© ì™„ë£Œ â†’ ./273K_time_horizontal.csv\n",
      "ì´ 8267ê°œ MOF ë³€í™˜ë¨\n",
      "âœ… Horizontal ë³‘í•© ì™„ë£Œ â†’ ./293K_time_horizontal.csv\n",
      "ì´ 7766ê°œ MOF ë³€í™˜ë¨\n",
      "âœ… Horizontal ë³‘í•© ì™„ë£Œ â†’ ./313K_time_horizontal.csv\n",
      "ì´ 8267ê°œ MOF ë³€í™˜ë¨\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from functools import reduce\n",
    "\n",
    "def merge_time_data_horizontal(T2: int):\n",
    "    \"\"\"\n",
    "    TIME CSVë“¤ì„ MOF ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©í•´\n",
    "    HENRY~15barê¹Œì§€ ì—´ë¡œ ê°–ëŠ” horizontal pivot ìƒì„±\n",
    "\n",
    "    ì˜ˆ: merge_time_data_horizontal(293) â†’ ./293K_time_horizontal.csv\n",
    "    \"\"\"\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # ê¸°ë³¸ ì„¤ì •\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    T = f\"{T2}K\"\n",
    "    base_path = f\"./{T}/TIME\"\n",
    "\n",
    "    PATHS = {\n",
    "        \"HENRY\": f\"{base_path}/{T2}_HENRY.csv\",\n",
    "        \"0.01\": f\"{base_path}/{T2}_0.01.csv\",\n",
    "        \"0.05\": f\"{base_path}/{T2}_0.05.csv\",\n",
    "        \"0.1\":  f\"{base_path}/{T2}_0.1.csv\",\n",
    "        \"0.5\":  f\"{base_path}/{T2}_0.5.csv\",\n",
    "        \"1\":    f\"{base_path}/{T2}_1.csv\",\n",
    "        \"5\":    f\"{base_path}/{T2}_5.csv\",\n",
    "        \"15\":   f\"{base_path}/{T2}_15.csv\"\n",
    "    }\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # 1ï¸âƒ£ ê° ì••ë ¥ íŒŒì¼ ì½ê¸°\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    for label, path in PATHS.items():\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"âš ï¸  Skip (file not found): {path}\")\n",
    "            continue\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "        df.columns = [c.strip().lower().replace(\" \", \"_\").replace(\"(s)\", \"s\") for c in df.columns]\n",
    "\n",
    "        # name ì»¬ëŸ¼ ë° time ì»¬ëŸ¼ ìë™ íƒì§€\n",
    "        name_col = [c for c in df.columns if \"mof\" in c.lower() or \"name\" in c.lower()][0]\n",
    "        time_col = [c for c in df.columns if \"time\" in c][0]\n",
    "\n",
    "        # name_baseì—ì„œ ì••ë ¥ ë¶€ë¶„ ì œê±° (ê³µí†µ ì‹ë³„ì í†µì¼)\n",
    "        def clean_name(name):\n",
    "            return re.sub(r\"_\\d+(?:\\.\\d+)?bar.*\", \"\", str(name))\n",
    "        df[\"name_base\"] = df[name_col].apply(clean_name)\n",
    "\n",
    "        # í•„ìš” ì—´ë§Œ ë‚¨ê¸°ê³  rename\n",
    "        df = df[[\"name_base\", time_col]].rename(columns={time_col: label})\n",
    "        dfs.append(df)\n",
    "\n",
    "    if not dfs:\n",
    "        raise RuntimeError(\"âŒ No valid TIME CSV files found.\")\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # 2ï¸âƒ£ name_base ê¸°ì¤€ ë³‘í•©\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    merged_df = reduce(lambda left, right: pd.merge(left, right, on=\"name_base\", how=\"outer\"), dfs)\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # 3ï¸âƒ£ ì—´ ìˆœì„œ ì •ë ¬\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    order = [\"name_base\", \"HENRY\", \"0.01\", \"0.05\", \"0.1\", \"0.5\", \"1\", \"5\", \"15\"]\n",
    "    merged_df = merged_df[[c for c in order if c in merged_df.columns]]\n",
    "\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # 4ï¸âƒ£ ì €ì¥\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    save_path = f\"./{T}_time_horizontal.csv\"\n",
    "    merged_df.to_csv(save_path, index=False)\n",
    "    print(f\"âœ… Horizontal ë³‘í•© ì™„ë£Œ â†’ {save_path}\")\n",
    "    print(f\"ì´ {len(merged_df)}ê°œ MOF ë³€í™˜ë¨\")\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# ì‹¤í–‰ (ì˜ˆì‹œ)\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "if __name__ == \"__main__\":\n",
    "    for T2 in [273, 293, 313]:\n",
    "        merge_time_data_horizontal(T2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "729e89a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8267\n",
      "7639\n",
      "7766\n",
      "7263\n",
      "8267\n",
      "7639\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import os \n",
    "KS = [273, 293, 313]\n",
    "for K in KS:\n",
    "    DF = pd.read_csv(f\"./{K}K_merged_dataset.csv\")\n",
    "    DF\n",
    "    with open(\"./04cif_list.txt\", \"r\") as f:\n",
    "        data = [x.strip() for x in f.readlines()]\n",
    "    print(len(DF))\n",
    "    DF = DF[DF[\"filename\"].isin(data)]\n",
    "    print(len(DF))\n",
    "    DF.to_csv(f\"./{K}K_merged_dataset.exclude.broken_cif.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a63468ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147\n",
      "0\n",
      "523\n",
      "0\n",
      "147\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "with open(\"./04cif_list.txt\", \"r\") as f:\n",
    "    data = [x.strip() for x in f.readlines()]\n",
    "data\n",
    "for K in KS:\n",
    "    K273 = pd.read_csv(f\"./{K}K_merged_dataset.exclude.broken_cif.csv\")[\"filename\"].to_list()\n",
    "    print(len(set(data) - set(K273)))\n",
    "    print(len(set(K273) - set(data)))\n",
    "    with open(f\"./ì¶”ê°€GCMC_ëˆ„ë½í•œê±´/04cif_list.{K}K.txt\", 'w') as f:\n",
    "        f.write('\\n'.join(list(set(data) - set(K273))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6057825e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>LCD</th>\n",
       "      <th>PLD</th>\n",
       "      <th>LFPD</th>\n",
       "      <th>cm3_g</th>\n",
       "      <th>ASA_m2_cm3</th>\n",
       "      <th>ASA_m2_g</th>\n",
       "      <th>NASA_m2_cm3</th>\n",
       "      <th>NASA_m2_g</th>\n",
       "      <th>AV_VF</th>\n",
       "      <th>...</th>\n",
       "      <th>NAV_cm3_g</th>\n",
       "      <th>Has_OMS</th>\n",
       "      <th>HENRY</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>1</th>\n",
       "      <th>5</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AFEKAX_clean</td>\n",
       "      <td>8.19182</td>\n",
       "      <td>6.99421</td>\n",
       "      <td>8.19182</td>\n",
       "      <td>0.987281</td>\n",
       "      <td>1565.630</td>\n",
       "      <td>1585.8000</td>\n",
       "      <td>78.053200</td>\n",
       "      <td>79.058700</td>\n",
       "      <td>0.6410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021477</td>\n",
       "      <td>0.107333</td>\n",
       "      <td>0.214545</td>\n",
       "      <td>1.026090</td>\n",
       "      <td>1.810673</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BICDAU_clean</td>\n",
       "      <td>11.50132</td>\n",
       "      <td>6.68644</td>\n",
       "      <td>11.17198</td>\n",
       "      <td>0.652990</td>\n",
       "      <td>2386.530</td>\n",
       "      <td>3654.7800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004437</td>\n",
       "      <td>0.022367</td>\n",
       "      <td>0.044683</td>\n",
       "      <td>0.221170</td>\n",
       "      <td>0.438653</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>BUKMUQ_clean</td>\n",
       "      <td>5.78794</td>\n",
       "      <td>5.06217</td>\n",
       "      <td>5.71305</td>\n",
       "      <td>0.851411</td>\n",
       "      <td>2895.400</td>\n",
       "      <td>3400.7100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006188</td>\n",
       "      <td>0.030482</td>\n",
       "      <td>0.061313</td>\n",
       "      <td>0.306049</td>\n",
       "      <td>0.605241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>c4ra13058h_c4ra13058h2_clean</td>\n",
       "      <td>5.16068</td>\n",
       "      <td>4.44688</td>\n",
       "      <td>5.16068</td>\n",
       "      <td>1.408960</td>\n",
       "      <td>1175.390</td>\n",
       "      <td>834.2260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052613</td>\n",
       "      <td>0.250177</td>\n",
       "      <td>0.467211</td>\n",
       "      <td>1.626260</td>\n",
       "      <td>2.355717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>cg801267m_si_001_clean</td>\n",
       "      <td>11.00208</td>\n",
       "      <td>5.91772</td>\n",
       "      <td>11.00208</td>\n",
       "      <td>0.888544</td>\n",
       "      <td>2113.710</td>\n",
       "      <td>2378.8500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.7066</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012008</td>\n",
       "      <td>0.061110</td>\n",
       "      <td>0.122621</td>\n",
       "      <td>0.602257</td>\n",
       "      <td>1.157064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7551</th>\n",
       "      <td>ZAXQUM_charged</td>\n",
       "      <td>5.30150</td>\n",
       "      <td>3.54171</td>\n",
       "      <td>4.69168</td>\n",
       "      <td>1.409490</td>\n",
       "      <td>721.003</td>\n",
       "      <td>511.5350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006039</td>\n",
       "      <td>0.030205</td>\n",
       "      <td>0.060211</td>\n",
       "      <td>0.270319</td>\n",
       "      <td>0.494686</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7552</th>\n",
       "      <td>ZAYJOA_charged</td>\n",
       "      <td>4.04003</td>\n",
       "      <td>3.48900</td>\n",
       "      <td>4.02141</td>\n",
       "      <td>3.849050</td>\n",
       "      <td>202.678</td>\n",
       "      <td>52.6567</td>\n",
       "      <td>0.041703</td>\n",
       "      <td>0.010835</td>\n",
       "      <td>0.3916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.007919</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7560</th>\n",
       "      <td>ZEDVOV_charged</td>\n",
       "      <td>5.91854</td>\n",
       "      <td>3.45718</td>\n",
       "      <td>5.91854</td>\n",
       "      <td>1.243490</td>\n",
       "      <td>557.924</td>\n",
       "      <td>448.6740</td>\n",
       "      <td>35.061100</td>\n",
       "      <td>28.195700</td>\n",
       "      <td>0.4732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>0.015473</td>\n",
       "      <td>0.030234</td>\n",
       "      <td>0.151258</td>\n",
       "      <td>0.278276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7561</th>\n",
       "      <td>ZEDVUB_charged</td>\n",
       "      <td>5.32930</td>\n",
       "      <td>4.32637</td>\n",
       "      <td>5.19907</td>\n",
       "      <td>1.331440</td>\n",
       "      <td>777.591</td>\n",
       "      <td>584.0230</td>\n",
       "      <td>24.990800</td>\n",
       "      <td>18.769800</td>\n",
       "      <td>0.4496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003076</td>\n",
       "      <td>0.015879</td>\n",
       "      <td>0.031505</td>\n",
       "      <td>0.153867</td>\n",
       "      <td>0.294281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7562</th>\n",
       "      <td>ZEDWAI_charged</td>\n",
       "      <td>5.28683</td>\n",
       "      <td>4.41255</td>\n",
       "      <td>5.26370</td>\n",
       "      <td>1.357180</td>\n",
       "      <td>819.018</td>\n",
       "      <td>603.4690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>0.032811</td>\n",
       "      <td>0.157222</td>\n",
       "      <td>0.301036</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>376 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          filename       LCD      PLD      LFPD     cm3_g  \\\n",
       "7                     AFEKAX_clean   8.19182  6.99421   8.19182  0.987281   \n",
       "28                    BICDAU_clean  11.50132  6.68644  11.17198  0.652990   \n",
       "36                    BUKMUQ_clean   5.78794  5.06217   5.71305  0.851411   \n",
       "40    c4ra13058h_c4ra13058h2_clean   5.16068  4.44688   5.16068  1.408960   \n",
       "74          cg801267m_si_001_clean  11.00208  5.91772  11.00208  0.888544   \n",
       "...                            ...       ...      ...       ...       ...   \n",
       "7551                ZAXQUM_charged   5.30150  3.54171   4.69168  1.409490   \n",
       "7552                ZAYJOA_charged   4.04003  3.48900   4.02141  3.849050   \n",
       "7560                ZEDVOV_charged   5.91854  3.45718   5.91854  1.243490   \n",
       "7561                ZEDVUB_charged   5.32930  4.32637   5.19907  1.331440   \n",
       "7562                ZEDWAI_charged   5.28683  4.41255   5.26370  1.357180   \n",
       "\n",
       "      ASA_m2_cm3   ASA_m2_g  NASA_m2_cm3  NASA_m2_g   AV_VF  ...  NAV_cm3_g  \\\n",
       "7       1565.630  1585.8000    78.053200  79.058700  0.6410  ...        0.0   \n",
       "28      2386.530  3654.7800     0.000000   0.000000  0.7824  ...        0.0   \n",
       "36      2895.400  3400.7100     0.000000   0.000000  0.7096  ...        0.0   \n",
       "40      1175.390   834.2260     0.000000   0.000000  0.5236  ...        0.0   \n",
       "74      2113.710  2378.8500     0.000000   0.000000  0.7066  ...        0.0   \n",
       "...          ...        ...          ...        ...     ...  ...        ...   \n",
       "7551     721.003   511.5350     0.000000   0.000000  0.4634  ...        0.0   \n",
       "7552     202.678    52.6567     0.041703   0.010835  0.3916  ...        0.0   \n",
       "7560     557.924   448.6740    35.061100  28.195700  0.4732  ...        0.0   \n",
       "7561     777.591   584.0230    24.990800  18.769800  0.4496  ...        0.0   \n",
       "7562     819.018   603.4690     0.000000   0.000000  0.4502  ...        0.0   \n",
       "\n",
       "      Has_OMS  HENRY      0.01      0.05       0.1       0.5         1   5  15  \n",
       "7           1    NaN  0.021477  0.107333  0.214545  1.026090  1.810673 NaN NaN  \n",
       "28          1    NaN  0.004437  0.022367  0.044683  0.221170  0.438653 NaN NaN  \n",
       "36          1    NaN  0.006188  0.030482  0.061313  0.306049  0.605241 NaN NaN  \n",
       "40          0    NaN  0.052613  0.250177  0.467211  1.626260  2.355717 NaN NaN  \n",
       "74          0    NaN  0.012008  0.061110  0.122621  0.602257  1.157064 NaN NaN  \n",
       "...       ...    ...       ...       ...       ...       ...       ...  ..  ..  \n",
       "7551        1    NaN  0.006039  0.030205  0.060211  0.270319  0.494686 NaN NaN  \n",
       "7552        0    NaN  0.000081  0.000406  0.000797  0.003978  0.007919 NaN NaN  \n",
       "7560        0    NaN  0.003055  0.015473  0.030234  0.151258  0.278276 NaN NaN  \n",
       "7561        0    NaN  0.003076  0.015879  0.031505  0.153867  0.294281 NaN NaN  \n",
       "7562        0    NaN  0.003206  0.016354  0.032811  0.157222  0.301036 NaN NaN  \n",
       "\n",
       "[376 rows x 21 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DF = pd.read_csv(\"./273K_merged_dataset.exclude.broken_cif.csv\")\n",
    "# ê²°ì¸¡ì¹˜ê°€ í•˜ë‚˜ë¼ë„ í¬í•¨ëœ í–‰ë§Œ í•„í„°ë§\n",
    "na_rows = DF[DF.isna().any(axis=1)]\n",
    "na_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2b8c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e09247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ CSV ë¡œë“œ ì™„ë£Œ: ./273K_merged_dataset.exclude.broken_cif.csv (7,639í–‰)\n",
      "ğŸ§¹ ê²°ì¸¡ì¹˜ ì œê±°: 376ê°œ í–‰ ì‚­ì œ (7263ê°œ ë‚¨ìŒ)\n",
      "\n",
      "ğŸ“Š [ìš”ì•½]\n",
      "ì…ë ¥ í”¼ì²˜: 12ê°œ\n",
      "ì €ì•• í”¼ì²˜: 1ê°œ\n",
      "ì˜ˆì¸¡ í”¼ì²˜: 0ê°œ\n",
      "ì¶œë ¥ í”¼ì²˜: 1ê°œ\n",
      "ìœ íš¨ ìƒ˜í”Œ: 7,263/7,639\n",
      "\n",
      "ğŸ” [ìƒ˜í”Œ ë°ì´í„°]\n",
      "                           filename       LCD       PLD      LFPD     cm3_g  \\\n",
      "0                      ACOCOM_clean  24.60642  13.03430  24.60642  0.349927   \n",
      "1                      ACOCUS_clean  24.38417  13.22222  24.38417  0.346494   \n",
      "2                      ACODAZ_clean  23.29182  13.11646  23.29182  0.343144   \n",
      "3    acscombsci.5b00188_34903_clean   6.15808   5.85025   6.15808  2.165830   \n",
      "4  acscombsci.5b00188_5013797_clean   9.69678   6.71185   9.61668  0.664961   \n",
      "\n",
      "   ASA_m2_cm3  ASA_m2_g  NASA_m2_cm3  NASA_m2_g   AV_VF  AV_cm3_g  NAV_cm3_g  \\\n",
      "0     1537.41  4393.520          0.0        0.0  0.8630   2.46623        0.0   \n",
      "1     1518.48  4382.420          0.0        0.0  0.8644   2.49471        0.0   \n",
      "2     1530.83  4461.210          0.0        0.0  0.8618   2.51148        0.0   \n",
      "3     1748.44   807.285          0.0        0.0  0.5420   0.25025        0.0   \n",
      "4     2272.90  3418.090          0.0        0.0  0.7302   1.09811        0.0   \n",
      "\n",
      "   Has_OMS     HENRY         1  \n",
      "0        1  0.000005  0.487727  \n",
      "1        1  0.000005  0.501413  \n",
      "2        1  0.000005  0.491670  \n",
      "3        0  0.000035  1.945599  \n",
      "4        0  0.000005  0.471141  \n",
      "âœ… Dataset ì¤€ë¹„ ì™„ë£Œ â†’ ì…ë ¥ 13ê°œ, ì¶œë ¥ 1ê°œ\n",
      "\n",
      "ğŸ§© [GCMCSampler Summary]\n",
      "   Sampler Type : qt_then_rd\n",
      "   Train/Test   : 3341 / 3922 (ratio=0.50)\n",
      "   Quantile/Random : 1525 / 1816\n",
      "   Quantile Col: HENRY\n",
      "   use_log=True, n_bins=125, gamma=0.3\n",
      "   Seed Base: 2025\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 23:42:46,278 | INFO | [TRAIN] Model=RF | Samples=3341 | Features=13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Plot saved â†’ ./plots/sampling_hist_HENRY.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 23:42:49,632 | INFO | [TIME] Training took 3.35 s\n",
      "2025-11-01 23:42:49,964 | INFO | [EVAL] R2=0.9820 | MAE=0.0172 | RMSE=0.0013 | MAPE=2.80%\n",
      "2025-11-01 23:42:50,629 | INFO | [SAVE] predictions â†’ ./run_rf\\predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from MOF_GCMC_SAMPLER import GCMCSampler\n",
    "import pandas as pd\n",
    "from MOF_GCMC_DATALOADER import load_mof_dataset\n",
    "\n",
    "df, meta = load_mof_dataset(\n",
    "    csv_path=\"./273K_merged_dataset.exclude.broken_cif.csv\",\n",
    "    input_features=[\"LCD\",\"PLD\",\"LFPD\",\"cm3_g\",\"ASA_m2_cm3\",\"ASA_m2_g\",\"NASA_m2_cm3\",\"NASA_m2_g\",\"AV_VF\",\"AV_cm3_g\",\"NAV_cm3_g\",\"Has_OMS\"],\n",
    "    lowp_features=[\"HENRY\"],\n",
    "    # pred_features=[\"pred_0.1\", \"pred_0.5\", \"pred_1\"],   # â† ì¶”ê°€ ì˜ˆì¸¡ ì»¬ëŸ¼\n",
    "    output_features=[\"1\"]\n",
    ")\n",
    "sampler = GCMCSampler(\n",
    "    sampler_type=\"qt_then_rd\",\n",
    "    qt_col=\"HENRY\",\n",
    "    use_log=True,\n",
    "    n_bins=125,\n",
    "    qt_frac=0.25,\n",
    "    train_ratio=0.5,\n",
    "    gamma=0.3,\n",
    "    seed_base=2025,\n",
    "    outdir=\"./plots\"\n",
    ")\n",
    "\n",
    "\n",
    "result = sampler.fit(df)\n",
    "sampler.summary(result, df=df)\n",
    "train_idx = result[\"train_idx\"]\n",
    "test_idx = result[\"test_idx\"]\n",
    "df_train = df.iloc[train_idx]\n",
    "df_test = df.iloc[test_idx]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from MOF_GCMC_MODEL import MOFModelTrainer\n",
    "\n",
    "# ì˜ˆì‹œ: ì´ë¯¸ samplerë¡œ train/test split ì™„ë£Œë¨\n",
    "X_train, X_test = df_train.drop(columns=[meta[\"meta_columns\"][0], meta[\"output_features\"][0]]), df_test.drop(columns=[meta[\"meta_columns\"][0], meta[\"output_features\"][0]])\n",
    "y_train, y_test = df_train[meta[\"output_features\"][0]], df_test[meta[\"output_features\"][0]]\n",
    "\n",
    "# ì™¸ë¶€ ìŠ¤ì¼€ì¼ëŸ¬ ì¤€ë¹„\n",
    "scaler_X = StandardScaler().fit(X_train)\n",
    "scaler_y = StandardScaler().fit(y_train.values.reshape(-1, 1))\n",
    "\n",
    "trainer = MOFModelTrainer(\n",
    "    model_type=\"rf\",\n",
    "    model_params={\"n_estimators\": 1000, \"max_depth\": None},\n",
    "    scaler_X=scaler_X,\n",
    "    scaler_y=scaler_y,\n",
    "    outdir=\"./run_rf\"\n",
    ")\n",
    "\n",
    "trainer.fit(X_train, y_train)\n",
    "metrics = trainer.evaluate(X_test, y_test)\n",
    "fi = trainer.feature_importance(X_test, y_test)\n",
    "pred_df = trainer.save_predictions(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "093dfb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‚ CSV ë¡œë“œ ì™„ë£Œ: ./273K_merged_dataset.exclude.broken_cif.csv (7,639í–‰)\n",
      "ğŸ§¹ ê²°ì¸¡ì¹˜ ì œê±°: 376ê°œ í–‰ ì‚­ì œ (7263ê°œ ë‚¨ìŒ)\n",
      "\n",
      "ğŸ“Š [ìš”ì•½]\n",
      "ì…ë ¥ í”¼ì²˜: 12ê°œ\n",
      "ì €ì•• í”¼ì²˜: 1ê°œ\n",
      "ì˜ˆì¸¡ í”¼ì²˜: 0ê°œ\n",
      "ì¶œë ¥ í”¼ì²˜: 1ê°œ\n",
      "ìœ íš¨ ìƒ˜í”Œ: 7,263/7,639\n",
      "\n",
      "ğŸ” [ìƒ˜í”Œ ë°ì´í„°]\n",
      "                           filename       LCD       PLD      LFPD     cm3_g  \\\n",
      "0                      ACOCOM_clean  24.60642  13.03430  24.60642  0.349927   \n",
      "1                      ACOCUS_clean  24.38417  13.22222  24.38417  0.346494   \n",
      "2                      ACODAZ_clean  23.29182  13.11646  23.29182  0.343144   \n",
      "3    acscombsci.5b00188_34903_clean   6.15808   5.85025   6.15808  2.165830   \n",
      "4  acscombsci.5b00188_5013797_clean   9.69678   6.71185   9.61668  0.664961   \n",
      "\n",
      "   ASA_m2_cm3  ASA_m2_g  NASA_m2_cm3  NASA_m2_g   AV_VF  AV_cm3_g  NAV_cm3_g  \\\n",
      "0     1537.41  4393.520          0.0        0.0  0.8630   2.46623        0.0   \n",
      "1     1518.48  4382.420          0.0        0.0  0.8644   2.49471        0.0   \n",
      "2     1530.83  4461.210          0.0        0.0  0.8618   2.51148        0.0   \n",
      "3     1748.44   807.285          0.0        0.0  0.5420   0.25025        0.0   \n",
      "4     2272.90  3418.090          0.0        0.0  0.7302   1.09811        0.0   \n",
      "\n",
      "   Has_OMS     HENRY         1  \n",
      "0        1  0.000005  0.487727  \n",
      "1        1  0.000005  0.501413  \n",
      "2        1  0.000005  0.491670  \n",
      "3        0  0.000035  1.945599  \n",
      "4        0  0.000005  0.471141  \n",
      "âœ… Dataset ì¤€ë¹„ ì™„ë£Œ â†’ ì…ë ¥ 13ê°œ, ì¶œë ¥ 1ê°œ\n",
      "\n",
      "ğŸ§© [GCMCSampler Summary]\n",
      "   Sampler Type : qt_then_rd\n",
      "   Train/Test   : 3632 / 3631 (ratio=0.50)\n",
      "   Quantile/Random : 0 / 3632\n",
      "   Quantile Col: HENRY\n",
      "   use_log=True, n_bins=125, gamma=0.3\n",
      "   Seed Base: 2025\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 23:43:05,484 | INFO | [TRAIN] Model=RF | Samples=3632 | Features=13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Plot saved â†’ ./plots/sampling_hist_HENRY.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-01 23:43:09,012 | INFO | [TIME] Training took 3.53 s\n",
      "2025-11-01 23:43:09,298 | INFO | [EVAL] R2=0.9700 | MAE=0.0223 | RMSE=0.0044 | MAPE=3.04%\n",
      "2025-11-01 23:43:10,058 | INFO | [SAVE] predictions â†’ ./run_rf\\predictions.csv\n"
     ]
    }
   ],
   "source": [
    "from MOF_GCMC_SAMPLER import GCMCSampler\n",
    "import pandas as pd\n",
    "from MOF_GCMC_DATALOADER import load_mof_dataset\n",
    "\n",
    "df, meta = load_mof_dataset(\n",
    "    csv_path=\"./273K_merged_dataset.exclude.broken_cif.csv\",\n",
    "    input_features=[\"LCD\",\"PLD\",\"LFPD\",\"cm3_g\",\"ASA_m2_cm3\",\"ASA_m2_g\",\"NASA_m2_cm3\",\"NASA_m2_g\",\"AV_VF\",\"AV_cm3_g\",\"NAV_cm3_g\",\"Has_OMS\"],\n",
    "    lowp_features=[\"HENRY\"],\n",
    "    # pred_features=[\"pred_0.1\", \"pred_0.5\", \"pred_1\"],   # â† ì¶”ê°€ ì˜ˆì¸¡ ì»¬ëŸ¼\n",
    "    output_features=[\"1\"]\n",
    ")\n",
    "sampler = GCMCSampler(\n",
    "    sampler_type=\"qt_then_rd\",\n",
    "    qt_col=\"HENRY\",\n",
    "    use_log=True,\n",
    "    n_bins=125,\n",
    "    qt_frac=0.0,\n",
    "    train_ratio=0.5,\n",
    "    gamma=0.3,\n",
    "    seed_base=2025,\n",
    "    outdir=\"./plots\"\n",
    ")\n",
    "\n",
    "\n",
    "result = sampler.fit(df)\n",
    "sampler.summary(result, df=df)\n",
    "train_idx = result[\"train_idx\"]\n",
    "test_idx = result[\"test_idx\"]\n",
    "df_train = df.iloc[train_idx]\n",
    "df_test = df.iloc[test_idx]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from MOF_GCMC_MODEL import MOFModelTrainer\n",
    "\n",
    "# ì˜ˆì‹œ: ì´ë¯¸ samplerë¡œ train/test split ì™„ë£Œë¨\n",
    "X_train, X_test = df_train.drop(columns=[meta[\"meta_columns\"][0], meta[\"output_features\"][0]]), df_test.drop(columns=[meta[\"meta_columns\"][0], meta[\"output_features\"][0]])\n",
    "y_train, y_test = df_train[meta[\"output_features\"][0]], df_test[meta[\"output_features\"][0]]\n",
    "\n",
    "# ì™¸ë¶€ ìŠ¤ì¼€ì¼ëŸ¬ ì¤€ë¹„\n",
    "scaler_X = StandardScaler().fit(X_train)\n",
    "scaler_y = StandardScaler().fit(y_train.values.reshape(-1, 1))\n",
    "\n",
    "trainer = MOFModelTrainer(\n",
    "    model_type=\"rf\",\n",
    "    model_params={\"n_estimators\": 1000, \"max_depth\": None},\n",
    "    scaler_X=scaler_X,\n",
    "    scaler_y=scaler_y,\n",
    "    outdir=\"./run_rf\"\n",
    ")\n",
    "\n",
    "trainer.fit(X_train, y_train)\n",
    "metrics = trainer.evaluate(X_test, y_test)\n",
    "fi = trainer.feature_importance(X_test, y_test)\n",
    "pred_df = trainer.save_predictions(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb68d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_total': 7639,\n",
       " 'n_valid': 7263,\n",
       " 'input_features': ['LCD',\n",
       "  'PLD',\n",
       "  'LFPD',\n",
       "  'cm3_g',\n",
       "  'ASA_m2_cm3',\n",
       "  'ASA_m2_g',\n",
       "  'NASA_m2_cm3',\n",
       "  'NASA_m2_g',\n",
       "  'AV_VF',\n",
       "  'AV_cm3_g',\n",
       "  'NAV_cm3_g',\n",
       "  'Has_OMS'],\n",
       " 'lowp_features': ['HENRY'],\n",
       " 'pred_features': [],\n",
       " 'output_features': ['1'],\n",
       " 'meta_columns': ['filename'],\n",
       " 'dropna': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
