# -*- coding: utf-8 -*-
"""
Single GCMC ML Case Runner (NN Version)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Runs one configuration (T, lowpâ†’outp, seed, sampling mode, qt_frac)
and saves results under a hierarchical directory.

Output structure:
RUN_FULL_EXP/
 â””â”€â”€ 293K/
     â””â”€â”€ 0.01_to_5/
         â””â”€â”€ NN/
             â”œâ”€â”€ trainratio_0_50/
             â”‚   â”œâ”€â”€ struct/
             â”‚   â”‚   â””â”€â”€ qtfrac_0_25/
             â”‚   â”‚       â””â”€â”€ seed_2025/
             â”‚   â”‚           â”œâ”€â”€ metrics.csv
             â”‚   â”‚           â”œâ”€â”€ train_log.csv
             â”‚   â”‚           â”œâ”€â”€ predictions.csv
             â”‚   â”‚           â”œâ”€â”€ predictions_full.csv
             â”‚   â”‚           â””â”€â”€ logs.txt
"""

import os
import argparse
import numpy as np
import pandas as pd
import logging
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm

from MOF_GCMC_DATALOADER import load_mof_dataset
from MOF_GCMC_SAMPLER import GCMCSampler
from MOF_GCMC_MODEL_NN import MOFModelTrainer   # âœ… ë‰´ëŸ´ë„· ë²„ì „ìœ¼ë¡œ êµì²´


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def setup_logger(log_path: str):
    """File + console logging setup"""
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s | %(levelname)s | %(message)s",
        handlers=[
            logging.FileHandler(log_path, mode="w", encoding="utf-8"),
            logging.StreamHandler()
        ]
    )
    logging.info(f"Logging started â†’ {log_path}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def run_single_case(args):
    np.random.seed(args.seed)
    combo = f"{args.lowp}_to_{args.outp}"

    # â”€â”€â”€ Hierarchical run directory â”€â”€â”€
    run_dir = os.path.join(
        args.out_root,
        args.temp,
        combo,
        "NN",
        f"trainratio_{args.train_ratio:.2f}".replace(".", "_"),
        args.mode,
        f"qtfrac_{args.qt_frac:.2f}".replace(".", "_"),
        f"seed_{args.seed}"
    )
    os.makedirs(run_dir, exist_ok=True)
    setup_logger(os.path.join(run_dir, "logs.txt"))

    logging.info(f"ðŸš€ Starting NN: {args.temp} | {combo} | mode={args.mode} | qt_frac={args.qt_frac:.2f} | seed={args.seed}")

    # â”€â”€â”€ Load dataset â”€â”€â”€
    data_path = f"../../00_GCMC/00_1st_collect/{args.temp}_merged_dataset.exclude.broken_cif.csv"
    if not os.path.exists(data_path):
        logging.error(f"Dataset not found: {data_path}")
        return

    df, meta = load_mof_dataset(
        csv_path=data_path,
        input_features=[
            "LCD", "PLD", "LFPD", "cm3_g", "ASA_m2_cm3", "ASA_m2_g",
            "NASA_m2_cm3", "NASA_m2_g", "AV_VF", "AV_cm3_g", "NAV_cm3_g", "Has_OMS"
        ],
        lowp_features=[args.lowp] if args.mode != "struct" else [],
        output_features=[args.outp]
    )

    target_col = meta["output_features"][0]
    id_col = meta["meta_columns"][0]

    # â”€â”€â”€ Sampler â”€â”€â”€
    if args.mode == "struct_with_input":
        sampler_type = "qt_then_rd"
        qt_col = args.lowp
    else:
        sampler_type = "random_struct"
        qt_col = None

    sampler = GCMCSampler(
        sampler_type=sampler_type,
        qt_col=qt_col,
        use_log=True,
        n_bins=100,
        qt_frac=args.qt_frac,
        train_ratio=args.train_ratio,
        gamma=0.5,
        seed_base=args.seed,
        outdir=run_dir
    )

    result = sampler.fit(df)
    sampler.summary(result, df)
    train_idx, test_idx = result["train_idx"], result["test_idx"]

    df_train, df_test = df.iloc[train_idx], df.iloc[test_idx]
    X_train = df_train.drop(columns=[id_col, target_col])
    y_train = df_train[target_col]
    X_test = df_test.drop(columns=[id_col, target_col])
    y_test = df_test[target_col]

    # â”€â”€â”€ Scaling â”€â”€â”€
    scaler_X = StandardScaler().fit(X_train)
    scaler_y = StandardScaler().fit(y_train.values.reshape(-1, 1))

    # â”€â”€â”€ Neural Network Model Parameters â”€â”€â”€
    params = {
        "input_dim": X_train.shape[1],
        "hidden_dim1": 128,
        "hidden_dim2": 64,
        "dropout": 0.1,
        "activation": "gelu",
        "lr": 1e-3,
        "epochs": 600,
        "patience": 50,
        "batch_size": 64,
        # ì¶”ê°€: low-pressure feature ì²˜ë¦¬
        "low_features": meta.get("lowp_features", []),
        "apply_log_to_low": len(meta.get("lowp_features", [])) > 0
    }

    trainer = MOFModelTrainer(
        model_type="nn",
        model_params=params,
        scaler_X=scaler_X,
        scaler_y=scaler_y,
        outdir=run_dir
    )

    # â”€â”€â”€ Train + Evaluate â”€â”€â”€
    trainer.fit(X_train, y_train, X_val=X_test, y_val=y_test)
    metrics = trainer.evaluate(X_test, y_test)

    # â”€â”€â”€ Save predictions â”€â”€â”€
    trainer.save_predictions(X_test, y_test)
    trainer.save_predictions_full(
        X_full=df.drop(columns=[target_col]),
        y_full=df[target_col],
        train_idx=train_idx,
        test_idx=test_idx,
        id_col=id_col
    )

    # â”€â”€â”€ Save summary â”€â”€â”€
    dfm = pd.DataFrame([{**vars(args), **metrics}])
    dfm.to_csv(os.path.join(run_dir, "metrics.csv"), index=False, encoding="utf-8-sig")

    logging.info(f"âœ… Finished NN case. Results saved at {run_dir}")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--temp", required=True, help="Temperature label (e.g., 273K)")
    parser.add_argument("--lowp", required=True, help="Low-pressure input feature")
    parser.add_argument("--outp", required=True, help="Target output pressure feature")
    parser.add_argument("--seed", type=int, required=True)
    parser.add_argument("--mode", choices=["struct", "struct_with_input"], required=True)
    parser.add_argument("--qt_frac", type=float, required=True)
    parser.add_argument("--train_ratio", type=float, default=0.5)
    parser.add_argument("--out_root", default="./RUN_FULL_EXP")
    parser.add_argument("--model", default="nn", choices=["nn"])
    args = parser.parse_args()
    run_single_case(args)
